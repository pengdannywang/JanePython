{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web   # Package and modules for importing data; this code may change depending on pandas version\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "# SARIMAX example\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import sys, getopt\n",
    "\n",
    "path='/root/pythondev/JanePython/'\n",
    "inputfile = path+'ASXListedCompanies.csv'\n",
    "outputfile = 'stocks.csv'\n",
    "\n",
    "def getStartDate(end,months):\n",
    "    day=end.day\n",
    "    year=end.year-months//12-1\n",
    "    month=months%12+1\n",
    "    start=datetime.datetime(year,month,day)\n",
    "    return start\n",
    "da=pd.read_csv(inputfile,header=1)\n",
    "tickers=da.iloc[:,1].tolist()\n",
    "scraped_tickers=[ticker+'.AX' for ticker in tickers]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.date.today()\n",
    "savepath=path+outputfile\n",
    "errorpath=path+'errors.csv'\n",
    "#end =datetime.datetime(end.year,end.month,1).date()\n",
    "\n",
    "\n",
    "errors=pd.DataFrame([],columns=['item'])\n",
    "errorexists=os.path.isfile(errorpath)\n",
    "print('exists error',errorexists)\n",
    "if(errorexists):\n",
    "    errors=pd.read_csv(errorpath,index_col=0)\n",
    "exists = os.path.isfile(savepath)\n",
    "print(savepath,'exists file',exists)\n",
    "months=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists:\n",
    "    exist_ds=pd.read_csv(savepath,parse_dates=['Date'],index_col='Date')\n",
    "ds =pd.DataFrame()\n",
    "exist_ds=pd.DataFrame()\n",
    "for item in scraped_tickers:\n",
    "    try:\n",
    "        if  len(errors)>0 and errors['item'].str.contains(item).any():\n",
    "            print(item,'occured an exception before. skip this time.')\n",
    "        else:\n",
    "            if(exists and exist_ds.columns.contains(item)):\n",
    "                start=exist_ds[item].index[-1].date()\n",
    "                print(item,' exists and update between',start,end,start<end)\n",
    "                res=None\n",
    "                new_end=end-timedelta(days=1)\n",
    "                if(start<new_end):\n",
    "                    remains=web.DataReader(item,\"yahoo\",start,new_end)['Adj Close']              \n",
    "                    res=exist_ds[item].combine_first(remains)\n",
    "                else:\n",
    "                    res=exist_ds[item]\n",
    "\n",
    "                exist_ds[item] =res\n",
    "                ds[item]=res\n",
    "            else:\n",
    "                start=getStartDate(end,months).date()\n",
    "                print(item,'is new and load from yahoo between',start,end,start<end)\n",
    "                res=web.DataReader(item,\"yahoo\",start,end)['Adj Close']\n",
    "                res=res.loc[~res.index.duplicated(keep='first')]\n",
    "                ds[item]=res\n",
    "                exist_ds[item] =res\n",
    "\n",
    "    except Exception as e: \n",
    "\n",
    "        da=pd.DataFrame([item],columns=errors.columns)\n",
    "        print(item,'write in errors.csv',e)\n",
    "        if(not str(e).find('No data fetched for symbol')==-1):\n",
    "            errors=errors.append(da,ignore_index=True)\n",
    "        pass\n",
    "if(exist_ds.isna().all().sum()>0):\n",
    "    exist_ds[exist_ds.columns[exist_ds.isna().all()]].dropna(axis=1,inplace=True)\n",
    "exist_ds.columns[exist_ds.isna().any()].any()\n",
    "#savepath='/Users/pengwang/Dropbox/finance/ttest.csv'\n",
    "errors.to_csv(errorpath)\n",
    "exist_ds.to_csv(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='MOQ.AX'\n",
    "start=getStartDate(end,months).date()\n",
    "print(ticker,'is new and load from yahoo between',start,end,start<end)\n",
    "res=web.DataReader(ticker,\"yahoo\",start,end)['Adj Close']\n",
    "ds[ticker]=res\n",
    "exist_ds[ticker] =res\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
