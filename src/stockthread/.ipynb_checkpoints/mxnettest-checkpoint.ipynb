{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_exists():\n",
    "    try:\n",
    "        mx.nd.zeros((1,), ctx=mx.gpu(0))\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "data_ctx = mx.cpu()\n",
    "if gpu_exists():\n",
    "    print('Using GPU for model_ctx')\n",
    "    model_ctx = mx.gpu(0)\n",
    "else:\n",
    "    print('Using CPU for model_ctx')\n",
    "    model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mx.random.seed(1)\n",
    "output_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAABhCAYAAACkn544AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGq5JREFUeJzt3X3c1fMdx/F3m2pJNN24mRItlBXCyN1oUhGjRMKiG0LbrDTNfUlYsVQy95OllJUmRUnrRsZqbLLclEpqJMldKdH+8Ph+zufnnOvmd13X+V3XOef1/Mfn8T13X79zOr/zu76f7+dTbceOHQIAAAAAoLS+V9kTAAAAAADkFi4kAQAAAACxcCEJAAAAAIiFC0kAAAAAQCxcSAIAAAAAYuFCEgAAAAAQCxeSAAAAAIBYuJAEAAAAAMTChSQAAAAAIBYuJAEAAAAAsewU587169ff0aRJkyxNJb+sWrVKGzZsqFaWx3Kc41myZMmGHTt2NCjLYznW8XCsk8OxTg7HOhmcF5PDZzo5HOvkcKyTEee7OtaFZJMmTbR48eKyzarAHHHEEWV+LMc5nmrVqq0u62M51vFwrJPDsU4OxzoZnBeTw2c6ORzr5HCskxHnu5rUVgAAAABALFxIAgAAAABi4UISAAAAABALF5IAAAAAgFi4kAQAAAAAxBKraiuA0unUqZMkacaMGTbWr18/i0eNGpX4nIBs2L59u8XVqqWqhX/99deSpBo1aiQ+J5Td9OnTJUkLFiywseHDh1v80ksvSZKOPPLIZCeGgrR+/XqLb775ZovHjh0rSRo0aJCN3XDDDRbXrFkzgdkBYEUSAAAAABALF5IAAAAAgFhIbUWZfPTRR5Kkgw8+2MZefvllixs3bpz4nCrbZ599ZvHcuXMlRVP9gHyxcOFCi6+55hqLd9ttN4tXrVolSbrvvvtsrE2bNtmfHEolpLBK0bT7tWvXSop+h7/33nsW77nnngnMLnd8+eWXFh944IGSpFatWtnYQw89ZHGDBg2Sm1iOe+WVVyRFG6P782mIb7/9dhvr2LGjxccdd1y2pwiU2aZNmyxevXq1xYceeqgk6XvfS63ztWzZ0uJXX301gdnFw4okAAAAACAWLiQBAAAAALFU2dTWzz//3OLHH3/c4smTJ0uSnn322YyPC+kOO3bssLHDDz/c4kaNGll89913S5L23nvvCphxYdm4caMk6YMPPrAxn2ISjm0heeGFFyz26U7BY489ZrE/VrVq1ZIUTVl4//33LQ6fZZ/W07RpU4ubNWtWnmkDpfbJJ59Ikvr06WNj4fMrSa+//rrFH3/8sSSpbdu2NjZnzhyLjznmmKzNE1Fr1qyRFE33CymsUvR8efHFF0uShgwZYmOcI4vmtzSEFOBwvCVp9uzZFnfv3j25ieWgTz/91OLLLrusVI+58MILLS70dFb/7/idd96RFO/3gX98RW7L8c+7bt06SdEU+ULaArR582ZJUu/evW1s2rRpFoeUVp/aWtWPDyuSAAAAAIBYqtSK5L///W+LzzzzTIvffffdtPv6q/VM/BV82LT93TgUjDnttNNs7He/+13G50DULrvsIkmqXbu2jS1btsxi31tup52q1MesQoVeeZJ00003pd0+dOhQi48//niL/V/ogmHDhln817/+Ne2+/vPoj+n5559vcShsks/HPK5t27ZZHFbQ/erxxIkTLQ498o466qi0MUkaOXKkxaeffrokaeedd67gGVddoZjO4sWLbcx/B4RMBSnVK9WvbJ1yyikWv/3225KkvfbaKzuTLXC+gEP4PPuefM2bN7f4yiuvtLhnz56SpO9///vZnmJemDVrVmVPIW88+OCDFvvvmExGjx4tSbr00kuzOqeq7ptvvrE4FDiTUoWfSvqtnLSQFRiyW6ToOSRfhOuL7wor6D5TIRN/Xpw6dWrFTSwLqtYnDAAAAABQ5XEhCQAAAACIpdLy33xq36JFiyRJZ5xxho35HitejRo1JEnnnnuujbVo0aLY1xo7dqzFfhN8SG/zaW6+X8upp55a7PMWsrDs/uMf/9jGfG+5LVu2WFynTp3kJpawt956y+J//vOfabf7dNayFgKYP3++JGnlypU2dvnll1v8yCOPWBxSWseMGWNj4d9MofrTn/5kcf/+/SUVXVQgjPsee/6+Po04fAeNHz++gmdc9RWVirT77rtbfN1110mSnnvuORsL3/VSKiWwR48e2ZhiQQnp237rRpcuXSz+8MMPJUldu3a1MX9erFevXranmLf8OQDx/fnPf7b4qquuSrvd96m9+eabk5hSTgjnJZ/OesABB2TltRo2bChJ+uqrr2zMb+nwBad8waRC49Ox/faYsqQXh60hktSkSZNyzSvbWJEEAAAAAMTChSQAAAAAIJZEU1t9iti9995r8RVXXJF238aNG1s8cOBAi0P/surVq5f6dX0lVt/Lz/cfCgYMGGAxqa1R/v0LPQ99CrJPpcrndFavqLSm9u3bS4r2MC2rUH3Np8b6/p0+9SdUvfMVkH1V0v3226/c86mqfHXWF1980WJfkbJ169aSop/VQw45xOJM/+ZnzJhhsU9jnTBhgqRoSr5PuS90Ic36tttus7ETTzzR4pCGSWpr+YUKuEX15gypUb4nMyqGTyfMVI0bxXv55ZctzlQpn3TWzML5Lk46a926dS1u1aqVxZk+t/69CL8xQg9ISfrJT35i8fPPP2/xrbfeKilalbVQ7LHHHhX2XP68OWXKFIvPOeccizt16lRhr1cerEgCAAAAAGJJdEXSF1rItArp+1bNnDnT4oMOOqjC5lDSFbxfnUB0E/VJJ51k8ZIlS9Lu26ZNm0TmVJU8+eSTGcdHjBghSapVq1apn2vcuHEW+79sdevWTZI0Z84cG/NFCfym7rDi4zd9+8906Ef085//vNTzyhV+ldb//911110W9+3bV1K8jAa/SunjN998U5K0dOlSG2NFMp1fSQ/HX0oVEwhZJpJ08MEHJzexHLdixQqLfS/koGnTphb7cy8qlu8XF1Zx/ApPgwYNEp9TVbd8+XKLi+qRl+k3Ikpv1113lRT93eYzFnz2XXmFTB8pla3mM6G8tm3bSsrPPrW+p6ePM/Eryb5AUVj19cUbfeyzokIhQX8OrQysSAIAAAAAYuFCEgAAAAAQS6Kpre+++26xt/ul4I4dOxZ737PPPtvi0K9Mknbbbbe0+/oNwoMGDSr2ednY/a1QRGfo0KE25tNZw7J8ofbQ2rx5syRpwYIFGW9v1qxZ7Of8wQ9+YPHo0aNL/bijjz7a4lDE6re//a2NffHFFxZ3795dknTPPffYWOfOnWPPtSry/SJD3ytJ+tWvfpWV1wtpmr5oAYqXqR/WyJEjLb7//vsTnE1u80W2Qn/kovr61q9fP7mJFZhJkyYVe3tRBZAK2RNPPGFx6HH6Xf53HYrmfzf4InLhu+D666/Pyuv639X+Pfzf//5X7ONCwS8/73zhj7XvHem3dLRr105SdBuH30I2bdo0SdKwYcNKfL3QT9xvhfLF/5LCiiQAAAAAIBYuJAEAAAAAsSSa2loS37fG95HMxPceevTRRy3u16+fJOmdd96xMZ/mN3369LTnOuussyz2qUGFZsOGDRaHdJzQn0yK9t0MaVXNmzdPaHZVS6g0t3LlykqeSbQCae/evSVFK4J16NDB4vAe+38H+ZLa+vDDD1vsK7WWxfr16y3277GvkBuONcrHb1NA8Xw6ma/k96Mf/UhSNJ2VaqGVx/9+ycfqlOX1+9//3mKfAnjsscdaHKqOIrNw3Pzv22xvzQop9JLUv39/i4uqvBv4auY1atSo+IlVsi+//FJSasuTFO2l7ns//uxnPyv2ucLj/va3v9nY1q1bLfa/yYMLLrjAYr99JGy9yrTlryKxIgkAAAAAiIULSQAAAABALImmtnbq1Mni2267zeJQQfKWW26xsfPOO69Mr7F69WpJ0RQJn6bm7bXXXpKkO+64w8Z8em0heOqppywOacFSqsLuL3/5SxvzFRXDcfa6du2ajSlWSZlSWo888kiLfbpOZTjhhBMsPvPMMy0OFdMmT55sY75qZi6nE/km4L6SbRzbtm2TJF177bU25tOA33jjDYtDushLL71kYz71Fel8RT//fqF0evToYbH/Dj7ssMMkkc6alP/85z8WL1q0KO32q6++2uJ8rE5ZXv786H9ztWzZ0uKaNWsW+xxbtmyRFP1OGT58eMbnDVtw/PacunXrxp12lRK2tFRkOuv7779v8WuvvZZ2+4MPPmhxUems3bp1kyTts88+NuYrTNeuXbvc86wKQjqrlEovDhVXpeg1TEnprF6o+P/KK6/YmE+Z9dt2wra+N99808aWLVtm8cyZMyWl3pNsYUUSAAAAABBLoiuSfvPpgAEDLA593krzl7vt27dLkj7++GMb8/2GpkyZIknauHFjxsfvu+++Fs+bN0+S1KhRoxJfNx+EY9KzZ08b8xt6fYGAMWPGSJIuu+wyG/N/RfQ9+4KwwltI/KqKL9pUlQosDBkyxOKJEydKivaW9D0r/UpcrunVq5fFTz75pMVx+ki++OKLkqKFe/x7/Omnn1ocViT322+/+JMtIOE7W5L+8pe/WBxWDPbff//E55RLfGG5OXPmZLzPqaeemtR0oOgqUKYspkItQpdtYRVSShUY8atA/rs60/vis89WrVqVhRnmjo8++sjiuXPnSpJmz55tY371sSTnn3++xSNGjJCU/9kRAwcOtPiBBx5Iu91nWJbXzjvvbLEvVBX+DWTqzyxJt99+uyRWJAEAAAAAVQwXkgAAAACAWCqtj6RPk4yzGf2hhx6SFE25zMQXDenTp4/FvshPZRdEqWhr166VJH322Wc25jfsXnHFFZKiacG+mI4vENCiRYu05//6668tHjduXAXMOHeFQhc+fcYXwqhK/L+FTOk+Xbp0SXI6WdOuXTuLfQEhXxijVatWkqQPPvjAxi699NK05/IpUj6thMIZ8fnUsw8//DDt9oYNGyY5nZzm//2G3pGS1Ldv38qYTsHyBbYyadq0aUIzyS2+D2FpTZgwweKwNUOSnn76aUnRQib+XOZ764WCc/Pnz4/9+vnEb/kaPHiwxWPHjo39XP6347BhwyzO95TW4O9//7vF33zzjSSpbdu2NpbElrnwGr6wj+8vvGnTJknR3zt77LFHhc8jv66kAAAAAABZx4UkAAAAACCWSkttzbYrr7zS4htvvLESZ5JdPlUhpO0VVbE2E98Lx1eeClXnTjzxRBvzqa0bNmxIey7fd6h+/fqlnsOsWbMkpVJvc0GoaJYLfUdLqui45557JjST7DrmmGMs3n333S3+73//a3H//v0lRftl+ffwkksuSRvz/UEzpe0UUmrm1q1bJUWr15Yk9C79rvC9HKrfIh6fJhyq8vl0Ne+ggw6SVJiVtStS2Dbiq1574TgXSiX4uBYuXCgplQooRbcY/fSnP7U4bMvxFUH99/JVV10lKVWZsjhDhw6VJB1//PE2Fr7LpJJ7Vuai8Fn11VeXL19ucabK+17nzp0tPu2009JuP+WUUyzOl98QcfjPYvgM33nnnZUyF18NPXzWpdT5IGwJlKJVXysKK5IAAAAAgFhybkUybPCdMWOGjc2cOdPi0LPs0UcftTFfTMNvNM2F1aSS+H6F7du3lyQ988wzNnb44YdbvGTJEknRXkyTJk2qsLlkKlpSlOrVq1t8//33V9gckhIKsPhj+a9//cviyurrFlaNfZ8zX3Ap8O9VvqwI+c9Uy5YtLfaFL1q3bi1JatasWcbnCIV5fLGdQl/F8QUqQqbHq6++Wu7nPe644yRFP5+HHXZYuZ+3UGzbts3iF154QZJ08sknZ7xvOO/5/qpHHHGExflWeC5bwu8KX7DOq8jzaT4Kv7n8583/DvPnrfXr16fdfuutt1ocpz9weA7/XFOnTrU42332KsMnn3wiKbVyW5wOHTpIknr37m1jhxxyiMX0Sv7WfffdZ/GKFSsqcSZVC2cPAAAAAEAsXEgCAAAAAGLJudTW0MfNp+j4Yhrnnntu2pjvt+ULFPiCHLnKpyU+9thjpXqMLzSycuXKjPdZunSpJGnu3Lk25tOJQ9rETjulPkJnn312xudq0qSJJOmMM86wMZ8uGG7PJYMGDZIULeS0YMECi5NMbX3rrbcsDvMpKsXqwAMPlJSav5QfKd7F8X0gi0ppDcJx88fkpptuysq8qjJflCH0YJOkjh07SoqmmBWlV69ekqR169ZlvD2kYfrvggsvvDDjfS+66CJJUo0aNWxsn332sfi9996TlOqlK0ULEPg+Wr6vZS6rW7euxaEgie+vfP3111sc0viOPvpoG3v44Yctrqo9cKuacMz894P/TPrvGqTr1KlTsbevWrUqbcwf065du1pcq1atYp/LbzsZMWJE2u3hXJhPfBGoG264odj7+jT4u+66SxL9T0sS0q2l6NaCyvbEE09Y7Led1KtXT1K0v2U2sCIJAAAAAIiFC0kAAAAAQCw5l9qaSYsWLSweO3aspGj/Q88v8c6bN09S/lStLC3f86eo/j9t2rSRJPXp08fGfCXcUD336quvtjHfv6YQjRs3zuJQfc6n/pbX559/bvHll19u8YQJEyz2/bkCX53xkUcekSQ1bty4wuaV63zK9rBhwyRFU9dKSofNR76Ssq8MHVL7fDqf53vN/vCHP5QUTW3t3r27xWGbwvTp023snnvusdh/3ocPH572Wr6SYEjRD88ppVJrJWn8+PEZ55sL/PmpTp06Ge/zm9/8RlI0Nc2nt4dqu2PGjLGxIUOGWHzOOedYXFLKYCELlc/994PfskF1y+LtsssusR/j+/TGOb5+20mmdPZ8rBDt+4L73yPBCSecYLHvI5mL24uQ+j4P3/9StCJyuMY56qijsjoPViQBAAAAALFwIQkAAAAAiKXSUlt9ClSoflQRKTWhyfUbb7xhY61atbL4tddes7hnz56SoilAPo0LUbvuumva2HnnnVcJM6l8PkUk8NVwQwXdCy64wMZ8yoFveP/VV1+lPZdP95s8ebIkafbs2TZWVEPs8Brh34EkPf300xZTVbB4IWXNN2YuRP77M9N3tU9tDRWcpejn/fXXX5ck9e3b18ZGjx5tcabv2o0bN1pcVEXp4tSvX9/ifffdN/bjqyJfXfKBBx6wOFQol1LnNV+h3Kf5XnvttZKix99XyNy+fXvFTbjAXHfddZU9hZyzePFii/25dPPmzWn39Z9Nf66sXr162n1Xr15t8R133JF2e1FVoXOZr05b0nmrUaNGFpPOGp//3ZZpG9E//vEPi1u2bJnxOcI51P+G8ynJmzZtSnvML37xC4vXrFmTdrufi9/K5K99sokVSQAAAABALImuSIaN6pL0hz/8weKwMti+fftyv0ZYUfAFMvxrhaIDUqoXpe85WdRfEZCZLzSwYsWKSpxJssLmZd870/fyufjiiyVJTz31lI35Qhj+r6x//OMfi32t8Ncmv6Lp+VWI0N8v9JVDZr4HVOixJ6X+4ljoqwxhFVyKrkhmKrJTu3ZtizP1L/WPKSnjw/f2zYc+vxWtQ4cOFvvzZZcuXSRF+/SV1BPOF9jxq5eI8v04w/eDL4Dk+5midHyhG1+wL1PP3tAjVpLOOussizMVjLv33nst9gWRQtHAUaNGlW3CVVBYnfXH5Lnnniv2Mc8++6zFoTClFC3eh6J169bNYv9ZC32K/XH0GWr+sxhWIv2qvO9PGfqCF/V7z4+H3yn+usX3Ci5LcauyYEUSAAAAABALF5IAAAAAgFgSTW19/PHHLfZpgCHN4aSTTrKxovqUlZbvQVZS0QafxkVqa9H8exYUVfQl39WsWVNSNC3VF8MJBUimTJlS7tcKaRHt2rWzMd8jq3nz5hbXrVu33K9XCEIqipTqjShJrVu3llR0f9VCEef71/dKrci+qUjnU5X8eSukt/kiXSXx6YWZCpcUsi+++MJiX7QlfBdfcsklNhb6paJsBg4caPGxxx5rcSgw4t+LZ555ptTP63tgjxw5UlJ+fc7DlpeS0lm9DRs2WOx/Q0ycOFFStFhP6BVelLvvvtti/9u+tHyaba70rvVb5vzWC/97IvBp2kWlqZaWPx8PHjzY4tA/srI/16xIAgAAAABi4UISAAAAABBLonlImfrlSakeVz4ddf/997e4c+fOaY/xKZV+WX3hwoWSpFmzZtmYrzqYycknn1zs7fiW79EU+L5xhWjvvfe2eN68eRb3799fkvT888+X+rl8vzhfdTWktJKKVnF8xTXfG6pOnTqSOL6o+ny13GnTpkmKfq4HDBhgcej327ZtWxvr0aNHtqeYs3za3datW9Nu7969e5LTyWthm4gU3d40f/58SalzqR8ryrBhwyz2PSP9a+Bb/jf0okWLJEnLli2zseHDhxf7+HXr1lnsewmXVqY+jLnEf76uueaaCnveAw44QFI0tbhBgwYWV8Ue16xIAgAAAABiSXRF0vdgWb58ucUzZsyQlOqB911+03RFChuwQ09AFK9Vq1YWL1iwQFK0x1ah84WafOEdVD1Lly612Pd4KvQVduSmUKzC90n2MeK58847M46H3oU+ewTZceihh0qKl9VTSEIBljVr1thYo0aNyvWcfpWyUAspllYodCOlCkLdcsstpX78RRddZPGvf/1ri0PBxPK+l0liRRIAAAAAEAsXkgAAAACAWBJNbfUppFOnTrU4bNTt16+fjU2aNKlcr+WXhXv16mVxpv5P5e1ZWSjGjBmTMQZyxdtvvy0pVZxEivZ4Ov300xOfE4CqJRTtA6qqsCXD9zzesmWLxSHlNRRv+S6/ZWzUqFGSor1pfbGXsWPHSpLWrl1rY3HSOPORv24IPSN978hCwookAAAAACAWLiQBAAAAALEkmtoaeeGdUi9dr149SdKECRNszMcAUBFC6olPZ/VVWxs2bJj0lAAAKBN//vL9j0Mv9u3bt5f6uXx/1JJ6pQ4ePLjUz4v8xookAAAAACAWLiQBAAAAALFUWmorACRt/Pjxkf8CAACgbFiRBAAAAADEwoUkAAAAACAWLiQBAAAAALFwIQkAAAAAiKXajh07Sn/natU+lLQ6e9PJK/vu2LGjQVkeyHGOjWOdHI51cjjWyeFYJ4PjnByOdXI41snhWCej1Mc51oUkAAAAAACktgIAAAAAYuFCEgAAAAAQCxeSAAAAAIBYuJAEAAAAAMTChSQAAAAAIBYuJAEAAAAAsXAhCQAAAACIhQtJAAAAAEAsXEgCAAAAAGL5P2DsnIrSJULaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "#print(mnist['train_data'][0].shape)\n",
    "#plt.imshow(mnist['train_data'][0][0],cmap='Greys')\n",
    "\n",
    "n_samples = 10\n",
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n",
    "_, axarr = plt.subplots(1, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[i].imshow(mnist['train_data'][j][0], cmap='Greys')\n",
    "    #axarr[i].axis('off')\n",
    "    axarr[i].get_xaxis().set_ticks([])\n",
    "    axarr[i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = np.reshape(mnist['train_data'],(-1,28*28))\n",
    "test_data = np.reshape(mnist['test_data'],(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['test_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = train_data.shape[0]/batch_size\n",
    "train_iter = mx.io.NDArrayIter(data={'data': train_data}, label={'label': mnist['train_label']}, batch_size = batch_size)\n",
    "test_iter = mx.io.NDArrayIter(data={'data': test_data}, label={'label': mnist['test_label']}, batch_size = batch_size)\n",
    "#train_iter = mx.io.NDArrayIter(data={'data': train_data}, batch_size = batch_size)\n",
    "#test_iter = mx.io.NDArrayIter(data={'data': test_data}, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(gluon.HybridBlock):\n",
    "    def __init__(self, n_hidden=400, n_latent=2, n_layers=1, n_output=784, batch_size=100, act_type='relu', **kwargs):\n",
    "        self.soft_zero = 1e-10\n",
    "        self.n_latent = n_latent\n",
    "        self.batch_size = batch_size\n",
    "        self.output = None\n",
    "        self.mu = None\n",
    "        # note to self: requring batch_size in model definition is sad, not sure how to deal with this otherwise though\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        # self.use_aux_logits = use_aux_logits\n",
    "        with self.name_scope():\n",
    "            self.encoder = nn.HybridSequential(prefix='encoder')\n",
    "            for i in range(n_layers):\n",
    "                self.encoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.encoder.add(nn.Dense(n_latent*2, activation=None))\n",
    "\n",
    "            self.decoder = nn.HybridSequential(prefix='decoder')\n",
    "            for i in range(n_layers):\n",
    "                self.decoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.decoder.add(nn.Dense(n_output, activation='sigmoid'))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        h = self.encoder(x)\n",
    "        #print(h)\n",
    "        mu_lv = F.split(h, axis=1, num_outputs=2)\n",
    "        mu = mu_lv[0]\n",
    "        lv = mu_lv[1]\n",
    "        self.mu = mu\n",
    "        #eps = F.random_normal(loc=0, scale=1, shape=mu.shape, ctx=model_ctx)\n",
    "        # this would work fine only for nd (i.e. non-hybridized block)\n",
    "        eps = F.random_normal(loc=0, scale=1, shape=(self.batch_size, self.n_latent), ctx=model_ctx)\n",
    "        z = mu + F.exp(0.5*lv)*eps\n",
    "        y = self.decoder(z)\n",
    "        self.output = y\n",
    "\n",
    "        KL = 0.5*F.sum(1+lv-mu*mu-F.exp(lv),axis=1)\n",
    "        logloss = F.sum(x*F.log(y+self.soft_zero)+ (1-x)*F.log(1-y+self.soft_zero), axis=1)\n",
    "        loss = -logloss-KL\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=400\n",
    "n_latent=2\n",
    "n_layers=2 # num of dense layers in encoder and decoder respectively\n",
    "n_output=784\n",
    "model_prefix = 'vae_gluon_{}d{}l{}h.params'.format(n_latent, n_layers, n_hidden)\n",
    "\n",
    "net = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(), ctx=model_ctx)\n",
    "net.hybridize()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': .001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7859dd7c16412ea41ac957e424c86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=50, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0, Training loss 184.74, Validation loss 171.10\n",
      "Epoch5, Training loss 149.94, Validation loss 152.46\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "print_period = n_epoch // 10\n",
    "start = time.time()\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "for epoch in tqdm_notebook(range(n_epoch), desc='epochs'):\n",
    "    epoch_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    train_iter.reset()\n",
    "    test_iter.reset()\n",
    "\n",
    "    n_batch_train = 0\n",
    "    for batch in train_iter:\n",
    "        n_batch_train +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        with autograd.record():\n",
    "            loss = net(data)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        epoch_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    n_batch_val = 0\n",
    "    for batch in test_iter:\n",
    "        n_batch_val +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        loss = net(data)\n",
    "        epoch_val_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    epoch_loss /= n_batch_train\n",
    "    epoch_val_loss /= n_batch_val\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    validation_loss.append(epoch_val_loss)\n",
    "\n",
    "    if epoch % max(print_period,1) == 0:\n",
    "        tqdm.write('Epoch{}, Training loss {:.2f}, Validation loss {:.2f}'.format(epoch, epoch_loss, epoch_val_loss))\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters(model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = np.linspace(1, n_epoch, len(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(validation_loss))\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n",
    "net2.load_parameters(model_prefix, ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.reset()\n",
    "test_batch = test_iter.next()\n",
    "net2(test_batch.data[0].as_in_context(model_ctx))\n",
    "result = net2.output.asnumpy()\n",
    "original = test_batch.data[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "idx = np.random.choice(batch_size, n_samples)\n",
    "_, axarr = plt.subplots(2, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[0,i].imshow(original[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[0,i].set_title('original')\n",
    "    #axarr[0,i].axis('off')\n",
    "    axarr[0,i].get_xaxis().set_ticks([])\n",
    "    axarr[0,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    axarr[1,i].imshow(result[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[1,i].set_title('reconstruction')\n",
    "    #axarr[1,i].axis('off')\n",
    "    axarr[1,i].get_xaxis().set_ticks([])\n",
    "    axarr[1,i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "counter = 0\n",
    "results = []\n",
    "labels = []\n",
    "for batch in test_iter:\n",
    "    net2(batch.data[0].as_in_context(model_ctx))\n",
    "    results.append(net2.mu.asnumpy())\n",
    "    labels.append(batch.label[0].asnumpy())\n",
    "    counter +=1\n",
    "    if counter >= n_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= np.vstack(results)\n",
    "labels = np.hstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.shape[1]==2:\n",
    "    from scipy.special import ndtri\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    fig, axarr = plt.subplots(1,2, figsize=(10,4))\n",
    "    im=axarr[0].scatter(result[:, 0], result[:, 1], c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[0].set_title(r'scatter plot of $\\mu$')\n",
    "    axarr[0].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[0])\n",
    "\n",
    "    im=axarr[1].scatter(norm.cdf(result[:, 0]), norm.cdf(result[:, 1]), c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[1].set_title(r'scatter plot of $\\mu$ on norm.cdf() transformed coordinates')\n",
    "    axarr[1].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[1])\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_for_test_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "zsamples = nd.array(np.random.randn(n_samples*n_samples, n_latent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.empty((28*n_samples, 28*n_samples))\n",
    "for i, img in enumerate(images):\n",
    "    x = i // n_samples\n",
    "    y = i % n_samples\n",
    "    canvas[(n_samples-y-1)*28:(n_samples-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "if output_fig:\n",
    "    plt.savefig('generated_samples_with_{}D_latent_space.png'.format(n_latent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_latent==2:\n",
    "    n_pts = 20\n",
    "\n",
    "    idx = np.arange(0, n_pts)\n",
    "\n",
    "    x = np.linspace(norm.cdf(-3), norm.cdf(3),n_pts)\n",
    "    x = ndtri(x)\n",
    "\n",
    "    x_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(x,n_latent,1)]))\n",
    "    id_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(idx,n_latent,1)]))\n",
    "\n",
    "    zsamples = nd.array(x_grid.reshape((n_latent, -1)).transpose())\n",
    "    zsamples_id = id_grid.reshape((n_latent, -1)).transpose()\n",
    "\n",
    "    images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()\n",
    "\n",
    "    #plot\n",
    "    canvas = np.empty((28*n_pts, 28*n_pts))\n",
    "    for i, img in enumerate(images):\n",
    "        x, y = zsamples_id[i]\n",
    "        canvas[(n_pts-y-1)*28:(n_pts-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_scan_for_generation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
