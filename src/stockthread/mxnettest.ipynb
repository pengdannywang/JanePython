{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for model_ctx\n"
     ]
    }
   ],
   "source": [
    "def gpu_exists():\n",
    "    try:\n",
    "        mx.nd.zeros((1,), ctx=mx.gpu(0))\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "data_ctx = mx.cpu()\n",
    "if gpu_exists():\n",
    "    print('Using GPU for model_ctx')\n",
    "    model_ctx = mx.gpu(0)\n",
    "else:\n",
    "    print('Using CPU for model_ctx')\n",
    "    model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mx.random.seed(1)\n",
    "output_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAABhCAYAAACkn544AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGd1JREFUeJzt3Xu4VGUVx/HfMZIsUUQwREHkQaNCQCJF8ZKIqYGomRQqVmbiFUrjPCpy04SQi5IQgSJqghqVGSoGdhPtIuANbyigiCIoCt4iETj94fOus8az58y858zMmZnz/fzDet65veyzZ8/seddeq6KqqkoAAAAAAGRrp4aeAAAAAACgtHAiCQAAAACIwokkAAAAACAKJ5IAAAAAgCicSAIAAAAAonAiCQAAAACIwokkAAAAACAKJ5IAAAAAgCicSAIAAAAAonAiCQAAAACI0iTmzi1btqxq3759nqZSXl555RVt3Lixoi6PZTvHWbZs2caqqqpWdXks2zoO27pw2NaFw7YuDD4XC4d9unDY1oXDti6MmGN11Ilk+/bttXTp0rrNqpHp0aNHnR/Ldo5TUVGxpq6PZVvHYVsXDtu6cNjWhcHnYuGwTxcO27pw2NaFEXOsJrUVAAAAABCFE0kAAAAAQBROJAEAAAAAUTiRBAAAAABE4UQSAAAAABAlqmorAAAofc8995zFU6ZMsXjmzJmSpMrKShsbPHiwxR06dCjA7AAApYAVSQAAAABAFE4kAQAAAABRyiK19bXXXrO4bdu2kqSKiorE+27ZssXipk2b5ndiAAAUiX//+98Wn3zyyRZv3LjR4p12+uT35YkTJ9rYnDlzLH766aclSS1atMjbPIEkH3/8scXDhg2TlJqWHcYkaezYsRY3aVIWX3WBosSKJAAAAAAgCieSAAAAAIAoZbfeH9JyUHp+9atfWXzRRRdZXFVV1RDTKZgnnnhCktS9e3cb86nZ4f9/1FFH2diDDz5o8S677JLvKQIoMR999JHF48ePlyRdf/31Nvbee+9l/VxvvPFG4vOWk23btln84osvWtytW7fE+wT+86lz586SpBtvvNHGevXqZfFnP/vZ3Ey2EfH73g9/+EOLFy1aJCn1O9+kSZMsHjp0qMX77LNPPqcI1GrkyJEWT5gwocbt3/3udy2+9dZbCzGlnOKsCwAAAAAQpexWJBEn3SrgtGnTJEkXXnhh3uewYsWKGq/fmLz88suS0heICuOLFy+2sb333tviyZMnW3zOOefkY4oASoBfZTzttNMs/utf/1rr43r06GFxx44dJUl33XVXjmdXnN5//31J0hVXXGFj06dPT7xv0jHaj4XenMcee6yNHXLIIRY/+uijFpM9VbsNGzZIknr27GljvrBi2H79+vWzMV9Ux69Obt++XZI0YMAAGzv88MMtTvfZC8RYt26dxYcddpjFr7/+usVJGXZz5861ePTo0ZKk9u3b536CecKRDAAAAAAQhRNJAAAAAEAUUlsboZBKKqVPJ813SqufQ6dOnWrc/sILL+T19YvJoYceGv0Yn8J2ySWXWBzSdZK2KXLrrbfekiS1atWqgWfSsHwBkh07dli88847Z/W4+++/38bOPfdci99++22Lw/HigAMOqN9ky9R///tfSalFG5LSWZs1a2Zx165dLb733nstDvt1utTW6667TlJq4Z5Ss3XrVotDP81//OMfiff1aY+ht+aBBx5oYzfccIPFS5YskZR6fH7ssccsLvfCcfXl99kf/OAHklLTAr0FCxZIkvr06WNjYd+UUtOTX331VUnS1KlTbWzevHkWf/vb367HrIuH77Ppj8VJfEGphx56SFLqvn733XdbHPrPpksB9gWpwnavy/eaUuLTrMPlRe+++27i7d7FF18sKbV44re+9S2Lw+fmBx98YGPPPPOMxT7Vu1iwIgkAAAAAiMKJJAAAAAAgSlmktt5xxx01xvwSvK/GRh8n6corr0wcz3c6qU9nTZqDf/0vfelLeZ1LMQl9IHfddVcb8/2yQurVL3/5Sxv705/+ZPGWLVssPvLIIyVVp/L450f2QqqglLp9Z82aZfGIESMkpaal3HPPPQWYXcPz6aw+Dd5XFv7Xv/4lSWrevLmNhXQ0Sbrsssskpb7vfaW70F9Vqj5e+HS0xu6BBx6wOPQtXLhwYa2P6du3r8Vz5sxJvE9IbU3n+eefz3aKRcv3JgwprW3btrWxSy+91OITTjjBYp/SGvj3/x/+8AdJ0umnn574ug8//LDFxxxzTOy0y9L69est9p97SSmtBx98sMXhs86rrKy02B+XwuUft99+u42F449/rmK8TMH3bfWpu0n859PatWuzfo2Qcp0udTVTheGnnnrK4vAeKPfU1nHjxln861//usbtXbp0sfiqq66y+NRTT5VUXS1aSk3DDt/z/N998+bNFvsq0G3atJEkrV692sb8pSItW7bM5r9Sb6xIAgAAAACilOyKpL+QdebMmTVub9q0qcXXXHNNQeZU7ELPyPCLUaH5VUg/h3K50L2uwi9PfuXLr8j27t1bktSrVy8b84UuQgEIqbpAib9QPhQtQDW/quIvkA/bzf+qt3LlylqfKxQqaEz89rn55pst9r9oh31xypQpNjZmzBiLO3ToIEl69tlnbczv9371x69ONma+iMu1115rcSiG4flMhPnz50tKPYY0Nv4X/pEjR9a4PWR+SNKQIUMs/uc//2nxHnvsISn9ypVfZUji+3XiE37FN6lAyW677WaxLwDlv+Ml8Rk+YcXHH0eWL19ucXgv+cJJxcKvBvrt85e//EVSdR/q+thrr71S/k3nlVdesfjDDz9MvM+ee+5Z7/kUq7///e8W33TTTbXe169C+p6+y5Ytk1RddEdKLcg1cOBASdmtjofvLkuXLrWxgw46yOLw3jn77LNtbPjw4RmfNxYrkgAAAACAKJxIAgAAAACilGxq6xlnnGHxmjVrGnAmpSOkQng+rTRfBW4ypdQee+yxeX39Yhf6PW3fvr3W+/lUnssvv9ziN9980+KQZnnbbbfZWDmmtvoeWSHFxu9fzz33nMV+WwS+R6Hf7p///OclpV6k3q5dO4t9gYyQZhSKykipfbzKsbBXSA8cPXp04u2f+9znLA5Fzn73u9/ZWDgWSNI555wjKXO/Sam806Uy+d///mfxgAEDLE5KZw37r5S638cUdtm0aVOtt2dKfytWPhUvqUDf7NmzLb7vvvss9t8vQoEi36/T8/t6Ev/3acyefvppi1etWpV4nxYtWkiS/vOf/9hYSIePFY5L/fr1szGf2vrnP/+5Ts9bCP5zZMaMGRaH48KTTz5pY76gYUhD9b05R40aZbHfF8N2TffeDj0NjzjiCBvz28/zvYDLTbjMSEouTOTTXUNRnU8Ll+L5fTFceiBJu+++u6Tsvj+E7y7pijD98Y9/lCRdcMEFNuZTpX0h0vpgRRIAAAAAEIUTSQAAAABAlJJNbUV2fKpDUmppSCvN5+tedNFFNW73KbW+31MpC2kEUnVVUP9/CykL2YhJ4fHVLUM/o3LqHRlSd6dOnWpjL730ksWhkl+6HlgdO3a0+KSTTpKUmhrvhdQe31MundBrslOnTjbme5P5vp/lIvR8833DPF95OKT5+X6HvkJjEt/D0PdCPfPMM+MnW+LC/uUr/i1atKjWx/g+pn369KnT65533nm13j5+/Pg6PW+x86mvPl6yZInFXbt2rfG40INPSr48wfeZTHeMaixC2rRPtfY9e72QhlnXdNYkZ511lsW+D2Cohuyr7jZr1ixnr5sPIV23Z8+eNubjwKez1tXWrVslpV5G4/Xv39/iYt9u+RQqrkrpe2+GKuZNmlSffvk4xmc+8xlJ6ftFhstHvPPPP99ifzzyl0vFYkUSAAAAABCFE0kAAAAAQJSyTW0txsayxShfqa1XXnllrbePHTs2L69baGvXrrXYV1Tctm2bpOoG95L0k5/8xOJBgwZZ3Lx5c0mpKWzh8en4So6+YlcYb926dXb/gSLiK/n5FNHQbNenQPnU6MmTJ0tKTSvxqb2+KmguU35D1TufyrNy5cqcPX8x2m+//SRJEyZMsLFhw4Yl3jdUaM2Uzuo9/vjjFvv3wCmnnBI1z1IVUuyk6sqgCxcuTLyvr7oYUlrrejz3afm+4nE58almvtl3SKf2xwZ/fPHprCGVzPOVNEP1T/938JeUpEt3K2c+9feRRx6RJG3evDnxvvvuu6/F/jMy30LKvq8g261bt4K9frELn70bNmxIvL1NmzYWl2O18lzylc3zLRxvfIpruOxKkoYPH24xqa0AAAAAgIIp2xXJ0IOoscvUOzKX/IpaUmGfadOmWVwuPSN9UZbvfe97Fi9YsEBS6iqb/1Uo9GWSqlce5s2bV+tr+VVIX8Ao9IuSqi/a/sUvfpHV/IuJ335+ZWbkyJGSqgvlSKkFdFA4YfXm5z//eeLt/m+YdKF/JumKycQUqiplvudb0kqkXzXzfSLrUljHrxStW7fO4kz9bEtVyPyQpNWrV1scigf5QiwHHHBArc/li7L41fnAr2I29hUav60yZRYMHTrU4ny858PnMtBYhV7QucSKJAAAAAAgCieSAAAAAIAoJZfa+sILL0iSli9f3sAzKQ1Jqa1efVNMQ0ENKTmd1SuXfpHphP5AktS9e3dJUmVlpY354iFDhgyx+JZbbpEkPfbYYzbm+wqFVLPFixfb2OzZsxPn0LdvX0nSl7/85fj/QAPzvcVCb0ipOo3XF83JN98P0feDvOSSSywOxU58X6YrrrjC4tBzK/SmLAch/frdd9+1sXbt2lns98ts/14+xfLZZ5+12KcE5rKXXLEIvQrnzp1rY0k9d73vf//7Ftf3EgV/PPH7dWPgCxWNGTMm+vG+8Je/tCDwn4UbN260uHfv3hYfddRRkqoLWJWr+++/v9bbfbq2P5bmQ7pCUuESFd8TGCh14btjOG+SpOnTp+f8dViRBAAAAABE4UQSAAAAABCl5FJbx40bJym1qqMX+kMdffTRBZtTMUvqZ5UpBTVGptRZKbVaaznbY489LA49I/v162djN910k8W+0l9IjfrmN79pYxMnTrT4i1/8oiTp+OOPT3zd/v37W3z77bfXZepFwafjbtq0yeKwDa+99lobC6nDUnJvt0x8P6xQiVSSfvOb30iS7rzzThvzlf58SlzQuXNni33K29SpUyVJV199dfT8iklIwZSqK+j6tFN/PGnatGn08/uqjqEPnyRdc8010c9VSkJ6cKZ0vi5dulgcPv/qav78+RafeeaZtd7X9zycNWuWxeWUql1XPh1zn332sfj111+XlJru6mN/fA7vFf938Knx5ZLO7VOok/jqxEnH11zYsWOHpPQVK8Pfs5A9/lA+QoXyQl5+k47/PA2x/wzxfvrTn+bkNVmRBAAAAABEKYkVyRdffNHie++9t9b7ht5DLVu2zOucSoVfkQzFGfwKwooVKyyuS+GdbFY3/RwaG9/v0K+wnHDCCRZfd911klJXY4488kiLk/Zl32PLr/g2a9asnjNuOIMHD7bY/4IWCu8ceuihNnb44YdbXJdfAZcsWWKxX3EbNGiQJOnRRx+1Md8rNEmvXr2iX7+UfPzxxxaH/rx+5cSvDtfFk08+mTh+0EEH1et5i12mfl5hRXDEiBE2tttuu2X9/L6IUVgV8qtffr9P4lfSzz777KxftzHwf4dnnnnG4pUrV0pKzWjw/HvpxhtvlFRdbE2S7r77bovD957WrVvnYMYNJ1PWUiHe52vXrpUkzZkzJ/H2AQMG5H0OpSypV6r3jW98ozATaWD+mFpRUWHxrrvuWmOsEEJWi8+w8vuyLxoYtG/f3uLLL788J/NgRRIAAAAAEIUTSQAAAABAlJJIbX3qqacs9heSJrn55pvzPZ2S4tNVk9JQfdpJptRW3zMyU78z37emvr0qy4VPwfQ9E0Ma59e//nUb8wUaQlqOL0azaNEii9u0aZPzuTYEX8Al9FiTqtN8QypYOq+99prFS5curfW+flv6/TOkE8akqPhiP+WYxt28eXOL/WUGufLSSy9Z7FOHunXrlvPXKiY+lTvJqFGjJMX1i3znnXcs9r1YY/pEhtSns846K+vHNGY+zTWkeadL9/b7d0hZPu6442zMf9cJ6YSTJk3K3WQLxPeZTVcYsZD8Ng66du1q8bBhwwo5nZLg99WQBu/H/OdeuV/eEfg089AnWqruNT127Fgb8wW56sunxG/evNniUCwnXSp9+Bv5eYXCQFLuLgFkRRIAAAAAEIUTSQAAAABAlJJIbX344YdrvT302ZOkdu3a5Xs6JSupaqtPUfVprr///e8lpaazZqq+5lOwSGetnU+L6NOnjySpU6dONuZTW4MTTzzR4lymTRS7kGaaqV/kfvvtlxjnm5+Xr0B42223SSr9PpL5dscdd1jse6X6/nyN0Ve+8hVJqam/6YTj9YwZM2zs1Vdfzfq1KisrLQ4VeWMqxCI7PmV+zz33lFSdwiylfoZOmTJFknTVVVfZmO9VXMxCP01Jevvtt2vc7j/r/CUN9bVt2zaLhw8fbvGqVaskpfaJDNtXqq66iWo+TX727NmSUvffgQMHWlwul9dkEnpDS8mVfv2+7reJ78mbLf8d0B8D0qWxBv69Ffr/9uzZM/r1Y7AiCQAAAACIwokkAAAAACBK0aa2rl+/3uKZM2fWel+/xF7IlLZSEypKJlVv/fR4tlUrp02bZvGFF15Yj9mVvw8++MBiXzkrNLT2lbmeeOIJi0899VRJ0uTJk23MV9vKVVNZ5Faototkq1evlpR66UKofidlTmUud6effnrOn9OnWLVo0cJif+wmpbWwQgrzp4UKmb5SZqnw/6f999/f4pUrV0pKreruP/d86mm2Nm3aZPH48eMtnjhxYo3nnT9/vo2FauBI9tBDD9V6uz9+NBannXaaxRdccIHF06dPl5R6/uGPqUcffbTF4fIN32HCn+8Evuq2r0jvNWnyySncyJEjbez888+3OKTP5xsrkgAAAACAKEW1Irl161aLDzvsMIv9BdSBX5EZOnRofidWJpJWDDP1g0wnFAVgFTJ7v/3tby1+4IEHLA6/Kv3oRz+yMd/jKvwy2LFjx8THsyKJUrF9+3aLQzaDXyU7+eSTCz6nxsQXiJgzZ04DzqR0+BXBdevWSZIWLFhgY4cccojFoSdwNjZs2CBJ6tu3b+LtobBO+HwoVf47Ruh754Vic5J03333WdyqVatan/eWW26RlFqIJGzTTwsFqxpLUZhcWLZsWa23X3zxxQWaSXEKRckkad68eZKkjRs32pgvVOnjuvDHAL/6GFY6jzjiiHo9f32xIgkAAAAAiMKJJAAAAAAgSlHlTPgUkkw9sELfLInekbHSpaP6PpFJBXl8jyu//ZGd0FdQkr761a9aHLbrz372s8THNW/evMZYTI84FI5Pyb/hhhsacCbFyRecuv766yVJ5557ro3tu+++BZ9TQznwwAMlZe7PG8Nf8nHwwQdbHIpE5KOATzl67733LPYpfCEd+Atf+IKN+XTMTEJhNUk65ZRTJEkvv/xy4n1DYZhSL37k09XDMXHNmjU2tnTpUotjeu8lXfLki/V85zvfsdj3Ggdywfc5DmnAvl/j5s2bLd6yZUvWzxuKzHXv3t3GfOGohk5jTcKKJAAAAAAgCieSAAAAAIAoRZXaGqNDhw4NPYWy4NNcQ59JKTm11d+O7Pj+QD6Fx6c6DBkypNbnSErhQXH62te+1tBTKGrPP/98jbF0ffTK3YQJEyRJJ510ko3179/f4kzv+7322sviW2+9VVJqarBPn0dmy5cvt9j3i1u1apXFJ554oqTUHnCtW7eu8Vw+hXXhwoUWV1ZWWhwu5QnVWSVp2LBhFpfLscT31nv88cclpaa7PvLIIxbv2LEjMa6N38+nTJli8THHHBM/WaAOwnHX93t84403LPY9OUPV1bZt29rYj3/8Y4vDuU2vXr3yM9k8YEUSAAAAABClqFYkw0WmUmpRgNCjRar+xWn33Xcv3MQgiZ6RdeH30x49eli8ePFii0MfSP/Ltv8V/Oqrr65xu/9lG8WjoqIiMcYnknoX9u7duwFm0vB22WUXSdLxxx9vYx999FFDTafR88Ux/PHXC0U1MmXnrF692mLfH9s744wzJFX3U5VKv7BOJqFw3KJFi2xs06ZNFs+cOdPiFStWSJLuueceG/M9kwcOHCgptehJeE+h/s477zyLJ02a1IAzKU177723xYMGDUqMywUrkgAAAACAKJxIAgAAAACiFFVqa5Mm1dO56667EmPkT1I/M592g3g+1ebOO++0eMSIERbPnj1bUmq6zzvvvGNxSDEJqVCS1KVLl9xPFvW2//77W7xkyZIGnElxmjFjhsVdu3aVRFEYFAdfwC8UQpKk4cOHW/zmm2+m/JuN0aNHW+wLK3Xu3FlS6veexmLnnXe22Pd49J+LaFj+syx895g7d66N+f6pgwcPtpj04saHFUkAAAAAQBROJAEAAAAAURpfTgXS8lVZqdCae23atLF41qxZiTHKR/fu3Rt6CkXBp2n73oh9+vSRlFqtG2govvrnpZdemhgDjYU/Lo8aNUpSamrrZZddZvHf/vY3i8eNGyep8fYHboxYkQQAAAAAROFEEgAAAAAQhdRWAEDehCbuUmpFP9/wGgBQnEJF4/Xr19vYmDFjLJ4+fbrF77//viTpwQcftDFfpRflhxVJAAAAAEAUViQBAHlz3HHHWfzhhx824EwAALF22umTNadWrVrZ2NSpUxNjND6sSAIAAAAAonAiCQAAAACIUlFVVZX9nSsq3pK0Jn/TKSv7VVVVtcp8t5rYztHY1oXDti4ctnXhsK0Lg+1cOGzrwmFbFw7bujCy3s5RJ5IAAAAAAJDaCgAAAACIwokkAAAAACAKJ5IAAAAAgCicSAIAAAAAonAiCQAAAACIwokkAAAAACAKJ5IAAAAAgCicSAIAAAAAonAiCQAAAACI8n/N95kRUFLXdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load mnist\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "#print(mnist['train_data'][0].shape)\n",
    "#plt.imshow(mnist['train_data'][0][0],cmap='Greys')\n",
    "\n",
    "n_samples = 10\n",
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n",
    "_, axarr = plt.subplots(1, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[i].imshow(mnist['train_data'][j][0], cmap='Greys')\n",
    "    #axarr[i].axis('off')\n",
    "    axarr[i].get_xaxis().set_ticks([])\n",
    "    axarr[i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = np.reshape(mnist['train_data'],(-1,28*28))\n",
    "test_data = np.reshape(mnist['test_data'],(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = train_data.shape[0]/batch_size\n",
    "train_iter = mx.io.NDArrayIter(data={'data': train_data}, label={'label': mnist['train_label']}, batch_size = batch_size)\n",
    "test_iter = mx.io.NDArrayIter(data={'data': test_data}, label={'label': mnist['test_label']}, batch_size = batch_size)\n",
    "#train_iter = mx.io.NDArrayIter(data={'data': train_data}, batch_size = batch_size)\n",
    "#test_iter = mx.io.NDArrayIter(data={'data': test_data}, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(gluon.HybridBlock):\n",
    "    def __init__(self, n_hidden=400, n_latent=2, n_layers=1, n_output=784, batch_size=100, act_type='relu', **kwargs):\n",
    "        self.soft_zero = 1e-10\n",
    "        self.n_latent = n_latent\n",
    "        self.batch_size = batch_size\n",
    "        self.output = None\n",
    "        self.mu = None\n",
    "        # note to self: requring batch_size in model definition is sad, not sure how to deal with this otherwise though\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        # self.use_aux_logits = use_aux_logits\n",
    "        with self.name_scope():\n",
    "            self.encoder = nn.HybridSequential(prefix='encoder')\n",
    "            for i in range(n_layers):\n",
    "                self.encoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.encoder.add(nn.Dense(n_latent*2, activation=None))\n",
    "\n",
    "            self.decoder = nn.HybridSequential(prefix='decoder')\n",
    "            for i in range(n_layers):\n",
    "                self.decoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.decoder.add(nn.Dense(n_output, activation='sigmoid'))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        h = self.encoder(x)\n",
    "        #print(h)\n",
    "        mu_lv = F.split(h, axis=1, num_outputs=2)\n",
    "        mu = mu_lv[0]\n",
    "        lv = mu_lv[1]\n",
    "        self.mu = mu\n",
    "        #eps = F.random_normal(loc=0, scale=1, shape=mu.shape, ctx=model_ctx)\n",
    "        # this would work fine only for nd (i.e. non-hybridized block)\n",
    "        eps = F.random_normal(loc=0, scale=1, shape=(self.batch_size, self.n_latent), ctx=model_ctx)\n",
    "        z = mu + F.exp(0.5*lv)*eps\n",
    "        y = self.decoder(z)\n",
    "        self.output = y\n",
    "\n",
    "        KL = 0.5*F.sum(1+lv-mu*mu-F.exp(lv),axis=1)\n",
    "        logloss = F.sum(x*F.log(y+self.soft_zero)+ (1-x)*F.log(1-y+self.soft_zero), axis=1)\n",
    "        loss = -logloss-KL\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=400\n",
    "n_latent=2\n",
    "n_layers=2 # num of dense layers in encoder and decoder respectively\n",
    "n_output=784\n",
    "model_prefix = 'vae_gluon_{}d{}l{}h.params'.format(n_latent, n_layers, n_hidden)\n",
    "\n",
    "net = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(), ctx=model_ctx)\n",
    "net.hybridize()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': .001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "print_period = n_epoch // 10\n",
    "start = time.time()\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "for epoch in tqdm_notebook(range(n_epoch), desc='epochs'):\n",
    "    epoch_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    train_iter.reset()\n",
    "    test_iter.reset()\n",
    "\n",
    "    n_batch_train = 0\n",
    "    for batch in train_iter:\n",
    "        n_batch_train +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        with autograd.record():\n",
    "            loss = net(data)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        epoch_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    n_batch_val = 0\n",
    "    for batch in test_iter:\n",
    "        n_batch_val +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        loss = net(data)\n",
    "        epoch_val_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    epoch_loss /= n_batch_train\n",
    "    epoch_val_loss /= n_batch_val\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    validation_loss.append(epoch_val_loss)\n",
    "\n",
    "    if epoch % max(print_period,1) == 0:\n",
    "        tqdm.write('Epoch{}, Training loss {:.2f}, Validation loss {:.2f}'.format(epoch, epoch_loss, epoch_val_loss))\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters(model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = np.linspace(1, n_epoch, len(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(validation_loss))\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n",
    "net2.load_parameters(model_prefix, ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.reset()\n",
    "test_batch = test_iter.next()\n",
    "net2(test_batch.data[0].as_in_context(model_ctx))\n",
    "result = net2.output.asnumpy()\n",
    "original = test_batch.data[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "idx = np.random.choice(batch_size, n_samples)\n",
    "_, axarr = plt.subplots(2, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[0,i].imshow(original[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[0,i].set_title('original')\n",
    "    #axarr[0,i].axis('off')\n",
    "    axarr[0,i].get_xaxis().set_ticks([])\n",
    "    axarr[0,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    axarr[1,i].imshow(result[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[1,i].set_title('reconstruction')\n",
    "    #axarr[1,i].axis('off')\n",
    "    axarr[1,i].get_xaxis().set_ticks([])\n",
    "    axarr[1,i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "counter = 0\n",
    "results = []\n",
    "labels = []\n",
    "for batch in test_iter:\n",
    "    net2(batch.data[0].as_in_context(model_ctx))\n",
    "    results.append(net2.mu.asnumpy())\n",
    "    labels.append(batch.label[0].asnumpy())\n",
    "    counter +=1\n",
    "    if counter >= n_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= np.vstack(results)\n",
    "labels = np.hstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.shape[1]==2:\n",
    "    from scipy.special import ndtri\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    fig, axarr = plt.subplots(1,2, figsize=(10,4))\n",
    "    im=axarr[0].scatter(result[:, 0], result[:, 1], c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[0].set_title(r'scatter plot of $\\mu$')\n",
    "    axarr[0].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[0])\n",
    "\n",
    "    im=axarr[1].scatter(norm.cdf(result[:, 0]), norm.cdf(result[:, 1]), c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[1].set_title(r'scatter plot of $\\mu$ on norm.cdf() transformed coordinates')\n",
    "    axarr[1].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[1])\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_for_test_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "zsamples = nd.array(np.random.randn(n_samples*n_samples, n_latent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.empty((28*n_samples, 28*n_samples))\n",
    "for i, img in enumerate(images):\n",
    "    x = i // n_samples\n",
    "    y = i % n_samples\n",
    "    canvas[(n_samples-y-1)*28:(n_samples-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "if output_fig:\n",
    "    plt.savefig('generated_samples_with_{}D_latent_space.png'.format(n_latent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_latent==2:\n",
    "    n_pts = 20\n",
    "\n",
    "    idx = np.arange(0, n_pts)\n",
    "\n",
    "    x = np.linspace(norm.cdf(-3), norm.cdf(3),n_pts)\n",
    "    x = ndtri(x)\n",
    "\n",
    "    x_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(x,n_latent,1)]))\n",
    "    id_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(idx,n_latent,1)]))\n",
    "\n",
    "    zsamples = nd.array(x_grid.reshape((n_latent, -1)).transpose())\n",
    "    zsamples_id = id_grid.reshape((n_latent, -1)).transpose()\n",
    "\n",
    "    images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()\n",
    "\n",
    "    #plot\n",
    "    canvas = np.empty((28*n_pts, 28*n_pts))\n",
    "    for i, img in enumerate(images):\n",
    "        x, y = zsamples_id[i]\n",
    "        canvas[(n_pts-y-1)*28:(n_pts-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_scan_for_generation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
