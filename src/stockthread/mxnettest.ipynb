{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for model_ctx\n"
     ]
    }
   ],
   "source": [
    "def gpu_exists():\n",
    "    try:\n",
    "        mx.nd.zeros((1,), ctx=mx.gpu(0))\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "data_ctx = mx.cpu()\n",
    "if gpu_exists():\n",
    "    print('Using GPU for model_ctx')\n",
    "    model_ctx = mx.gpu(0)\n",
    "else:\n",
    "    print('Using CPU for model_ctx')\n",
    "    model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mx.random.seed(1)\n",
    "output_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load mnist\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "#print(mnist['train_data'][0].shape)\n",
    "#plt.imshow(mnist['train_data'][0][0],cmap='Greys')\n",
    "\n",
    "n_samples = 10\n",
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n",
    "_, axarr = plt.subplots(1, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[i].imshow(mnist['train_data'][j][0], cmap='Greys')\n",
    "    #axarr[i].axis('off')\n",
    "    axarr[i].get_xaxis().set_ticks([])\n",
    "    axarr[i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = np.reshape(mnist['train_data'],(-1,28*28))\n",
    "test_data = np.reshape(mnist['test_data'],(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = train_data.shape[0]/batch_size\n",
    "train_iter = mx.io.NDArrayIter(data={'data': train_data}, label={'label': mnist['train_label']}, batch_size = batch_size)\n",
    "test_iter = mx.io.NDArrayIter(data={'data': test_data}, label={'label': mnist['test_label']}, batch_size = batch_size)\n",
    "#train_iter = mx.io.NDArrayIter(data={'data': train_data}, batch_size = batch_size)\n",
    "#test_iter = mx.io.NDArrayIter(data={'data': test_data}, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAE(gluon.HybridBlock):\n",
    "    def __init__(self, n_hidden=400, n_latent=2, n_layers=1, n_output=784, batch_size=100, act_type='relu', **kwargs):\n",
    "        self.soft_zero = 1e-10\n",
    "        self.n_latent = n_latent\n",
    "        self.batch_size = batch_size\n",
    "        self.output = None\n",
    "        self.mu = None\n",
    "        # note to self: requring batch_size in model definition is sad, not sure how to deal with this otherwise though\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        # self.use_aux_logits = use_aux_logits\n",
    "        with self.name_scope():\n",
    "            self.encoder = nn.HybridSequential(prefix='encoder')\n",
    "            for i in range(n_layers):\n",
    "                self.encoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.encoder.add(nn.Dense(n_latent*2, activation=None))\n",
    "\n",
    "            self.decoder = nn.HybridSequential(prefix='decoder')\n",
    "            for i in range(n_layers):\n",
    "                self.decoder.add(nn.Dense(n_hidden, activation=act_type))\n",
    "            self.decoder.add(nn.Dense(n_output, activation='sigmoid'))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        h = self.encoder(x)\n",
    "        #print(h)\n",
    "        mu_lv = F.split(h, axis=1, num_outputs=2)\n",
    "        mu = mu_lv[0]\n",
    "        lv = mu_lv[1]\n",
    "        self.mu = mu\n",
    "        #eps = F.random_normal(loc=0, scale=1, shape=mu.shape, ctx=model_ctx)\n",
    "        # this would work fine only for nd (i.e. non-hybridized block)\n",
    "        eps = F.random_normal(loc=0, scale=1, shape=(self.batch_size, self.n_latent), ctx=model_ctx)\n",
    "        z = mu + F.exp(0.5*lv)*eps\n",
    "        y = self.decoder(z)\n",
    "        self.output = y\n",
    "\n",
    "        KL = 0.5*F.sum(1+lv-mu*mu-F.exp(lv),axis=1)\n",
    "        logloss = F.sum(x*F.log(y+self.soft_zero)+ (1-x)*F.log(1-y+self.soft_zero), axis=1)\n",
    "        loss = -logloss-KL\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=400\n",
    "n_latent=2\n",
    "n_layers=2 # num of dense layers in encoder and decoder respectively\n",
    "n_output=784\n",
    "model_prefix = 'vae_gluon_{}d{}l{}h.params'.format(n_latent, n_layers, n_hidden)\n",
    "\n",
    "net = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(), ctx=model_ctx)\n",
    "net.hybridize()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': .001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17576897678644e5bc4ba011b6908602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=50, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0, Training loss 186.26, Validation loss 172.32\n",
      "Epoch5, Training loss 150.06, Validation loss 151.55\n",
      "Epoch10, Training loss 144.65, Validation loss 146.39\n",
      "Epoch15, Training loss 142.04, Validation loss 143.97\n",
      "Epoch20, Training loss 140.92, Validation loss 143.69\n",
      "Epoch25, Training loss 139.47, Validation loss 142.55\n",
      "Epoch30, Training loss 139.46, Validation loss 141.91\n",
      "Epoch35, Training loss 137.88, Validation loss 140.83\n",
      "Epoch40, Training loss 137.78, Validation loss 140.47\n",
      "Epoch45, Training loss 137.03, Validation loss 140.44\n",
      "\n",
      "Time elapsed: 898.88s\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "print_period = n_epoch // 10\n",
    "start = time.time()\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "for epoch in tqdm_notebook(range(n_epoch), desc='epochs'):\n",
    "    epoch_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "\n",
    "    train_iter.reset()\n",
    "    test_iter.reset()\n",
    "\n",
    "    n_batch_train = 0\n",
    "    for batch in train_iter:\n",
    "        n_batch_train +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        with autograd.record():\n",
    "            loss = net(data)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        epoch_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    n_batch_val = 0\n",
    "    for batch in test_iter:\n",
    "        n_batch_val +=1\n",
    "        data = batch.data[0].as_in_context(model_ctx)\n",
    "        loss = net(data)\n",
    "        epoch_val_loss += nd.mean(loss).asscalar()\n",
    "\n",
    "    epoch_loss /= n_batch_train\n",
    "    epoch_val_loss /= n_batch_val\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    validation_loss.append(epoch_val_loss)\n",
    "\n",
    "    if epoch % max(print_period,1) == 0:\n",
    "        tqdm.write('Epoch{}, Training loss {:.2f}, Validation loss {:.2f}'.format(epoch, epoch_loss, epoch_val_loss))\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters(model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = np.linspace(1, n_epoch, len(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(validation_loss))\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size)\n",
    "net2.load_parameters(model_prefix, ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.reset()\n",
    "test_batch = test_iter.next()\n",
    "net2(test_batch.data[0].as_in_context(model_ctx))\n",
    "result = net2.output.asnumpy()\n",
    "original = test_batch.data[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "idx = np.random.choice(batch_size, n_samples)\n",
    "_, axarr = plt.subplots(2, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[0,i].imshow(original[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[0,i].set_title('original')\n",
    "    #axarr[0,i].axis('off')\n",
    "    axarr[0,i].get_xaxis().set_ticks([])\n",
    "    axarr[0,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    axarr[1,i].imshow(result[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[1,i].set_title('reconstruction')\n",
    "    #axarr[1,i].axis('off')\n",
    "    axarr[1,i].get_xaxis().set_ticks([])\n",
    "    axarr[1,i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "counter = 0\n",
    "results = []\n",
    "labels = []\n",
    "for batch in test_iter:\n",
    "    net2(batch.data[0].as_in_context(model_ctx))\n",
    "    results.append(net2.mu.asnumpy())\n",
    "    labels.append(batch.label[0].asnumpy())\n",
    "    counter +=1\n",
    "    if counter >= n_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= np.vstack(results)\n",
    "labels = np.hstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.shape[1]==2:\n",
    "    from scipy.special import ndtri\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    fig, axarr = plt.subplots(1,2, figsize=(10,4))\n",
    "    im=axarr[0].scatter(result[:, 0], result[:, 1], c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[0].set_title(r'scatter plot of $\\mu$')\n",
    "    axarr[0].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[0])\n",
    "\n",
    "    im=axarr[1].scatter(norm.cdf(result[:, 0]), norm.cdf(result[:, 1]), c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[1].set_title(r'scatter plot of $\\mu$ on norm.cdf() transformed coordinates')\n",
    "    axarr[1].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[1])\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_for_test_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "zsamples = nd.array(np.random.randn(n_samples*n_samples, n_latent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.empty((28*n_samples, 28*n_samples))\n",
    "for i, img in enumerate(images):\n",
    "    x = i // n_samples\n",
    "    y = i % n_samples\n",
    "    canvas[(n_samples-y-1)*28:(n_samples-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "if output_fig:\n",
    "    plt.savefig('generated_samples_with_{}D_latent_space.png'.format(n_latent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_latent==2:\n",
    "    n_pts = 20\n",
    "\n",
    "    idx = np.arange(0, n_pts)\n",
    "\n",
    "    x = np.linspace(norm.cdf(-3), norm.cdf(3),n_pts)\n",
    "    x = ndtri(x)\n",
    "\n",
    "    x_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(x,n_latent,1)]))\n",
    "    id_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(idx,n_latent,1)]))\n",
    "\n",
    "    zsamples = nd.array(x_grid.reshape((n_latent, -1)).transpose())\n",
    "    zsamples_id = id_grid.reshape((n_latent, -1)).transpose()\n",
    "\n",
    "    images = net2.decoder(zsamples.as_in_context(model_ctx)).asnumpy()\n",
    "\n",
    "    #plot\n",
    "    canvas = np.empty((28*n_pts, 28*n_pts))\n",
    "    for i, img in enumerate(images):\n",
    "        x, y = zsamples_id[i]\n",
    "        canvas[(n_pts-y-1)*28:(n_pts-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_scan_for_generation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
