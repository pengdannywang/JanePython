{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 2, linear)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Dense(2)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/lib/python3.6/site-packages/mxnet/gluon/parameter.py:689: UserWarning: Parameter 'dense0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/root/miniconda/lib/python3.6/site-packages/mxnet/gluon/parameter.py:689: UserWarning: Parameter 'dense0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.00952624 -0.01501013  0.05958354  0.04705103]\n",
       " [-0.06005495 -0.02276454 -0.0578019   0.02074406]]\n",
       "<NDArray 2x4 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "layer.initialize()\n",
    "x = nd.random.uniform(-1,1,(3,4))\n",
    "layer(x)\n",
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2D(None -> 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
       "  (2): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
       "  (4): Dense(None -> 120, Activation(relu))\n",
       "  (5): Dense(None -> 84, Activation(relu))\n",
       "  (6): Dense(None -> 10, linear)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "# Add a sequence of layers.\n",
    "net.add(# Similar to Dense, it is not necessary to specify the input channels\n",
    "        # by the argument `in_channels`, which will be  automatically inferred\n",
    "        # in the first forward pass. Also, we apply a relu activation on the\n",
    "        # output. In addition, we can use a tuple to specify a  non-square\n",
    "        # kernel size, such as `kernel_size=(2,4)`\n",
    "        nn.Conv2D(channels=6, kernel_size=5, activation='relu'),\n",
    "        # One can also use a tuple to specify non-symmetric pool and stride sizes\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # The dense layer will automatically reshape the 4-D output of last\n",
    "        # max pooling layer into the 2-D shape: (x.shape[0], x.size/x.shape[0])\n",
    "        nn.Dense(120, activation=\"relu\"),\n",
    "        nn.Dense(84, activation=\"relu\"),\n",
    "        nn.Dense(10))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net.initialize()\n",
    "# Input shape is (batch_size, color_channels, height, width)\n",
    "x = nd.random.uniform(shape=(4,1,28,28))\n",
    "y = net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1, 5, 5), (84,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net[0].weight.data().shape, net[5].bias.data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixMLP(\n",
       "  (blk): Sequential(\n",
       "    (0): Dense(None -> 3, Activation(relu))\n",
       "    (1): Dense(None -> 4, Activation(relu))\n",
       "  )\n",
       "  (dense): Dense(None -> 5, linear)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class MixMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Run `nn.Block`'s init method\n",
    "        super(MixMLP, self).__init__(**kwargs)\n",
    "        self.blk = nn.Sequential()\n",
    "        self.blk.add(nn.Dense(3, activation='relu'),\n",
    "                     nn.Dense(4, activation='relu'))\n",
    "        self.dense = nn.Dense(5)\n",
    "    def forward(self, x):\n",
    "        y = nd.relu(self.blk(x))\n",
    "        print(y)\n",
    "        return self.dense(y)\n",
    "\n",
    "net = MixMLP()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.0015199  0.         0.00076785 0.        ]\n",
      " [0.00133006 0.         0.00064367 0.        ]]\n",
      "<NDArray 2x4 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 3.5631478e-05 -1.5303296e-05  8.4307962e-05  5.4950986e-05\n",
       "   2.9626513e-05]\n",
       " [ 3.1893280e-05 -1.3741388e-05  7.3266892e-05  4.8983617e-05\n",
       "   2.7170252e-05]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "x = nd.random.uniform(shape=(2,2))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.05553398  0.03005757  0.06864745]\n",
       " [-0.0042704  -0.03963442 -0.00615795]\n",
       " [ 0.02283095  0.05689853 -0.03313487]\n",
       " [-0.05078914 -0.06710886 -0.0379093 ]]\n",
       "<NDArray 4x3 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.blk[1].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
