{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Feature Scaling\n",
    "# Use Normalization (versus Standardization) for RNNs with Sigmoid Activation Functions\n",
    "# 'MinMaxScalar' is a Normalization Library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ticker='DHG.AX'\n",
    "months=72\n",
    "end = datetime.date.today()\n",
    "day=end.day\n",
    "year=end.year-months//12-1\n",
    "month=months%12+1\n",
    "start=datetime.datetime(year,month,day)\n",
    "\n",
    "dataset_train=web.DataReader(ticker,\"yahoo\",start,end)  \n",
    "training_set = dataset_train.iloc[:, 0:1].values\n",
    "\n",
    "# 'feature_range = (0,1)' makes sure that training data is scaled to have values between 0 and 1\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps (look back 60 days) and 1 output\n",
    "# This tells the RNN what to remember (Number of timesteps) when predicting the next Stock Price\n",
    "# The wrong number of timesteps can lead to Overfitting or bogus results\n",
    "# 'x_train' Input with 60 previous days' stock prices\n",
    "X_train = []\n",
    "# 'y_train' Output with next day's stock price\n",
    "y_train = []\n",
    "for i in range(60, len(dataset_train)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        ],\n",
       "        [0.8983957 ],\n",
       "        [0.8502674 ],\n",
       "        ...,\n",
       "        [0.47860971],\n",
       "        [0.47593585],\n",
       "        [0.46524068]],\n",
       "\n",
       "       [[0.8983957 ],\n",
       "        [0.8502674 ],\n",
       "        [0.7967914 ],\n",
       "        ...,\n",
       "        [0.47593585],\n",
       "        [0.46524068],\n",
       "        [0.44919791]],\n",
       "\n",
       "       [[0.8502674 ],\n",
       "        [0.7967914 ],\n",
       "        [0.80748657],\n",
       "        ...,\n",
       "        [0.46524068],\n",
       "        [0.44919791],\n",
       "        [0.43315515]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.3529412 ],\n",
       "        [0.35828879],\n",
       "        [0.26203207],\n",
       "        ...,\n",
       "        [0.65775398],\n",
       "        [0.62032086],\n",
       "        [0.6470588 ]],\n",
       "\n",
       "       [[0.35828879],\n",
       "        [0.26203207],\n",
       "        [0.28342255],\n",
       "        ...,\n",
       "        [0.62032086],\n",
       "        [0.6470588 ],\n",
       "        [0.70053481]],\n",
       "\n",
       "       [[0.26203207],\n",
       "        [0.28342255],\n",
       "        [0.31550808],\n",
       "        ...,\n",
       "        [0.6470588 ],\n",
       "        [0.70053481],\n",
       "        [0.68983963]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshaping (add more dimensions)\n",
    "# This lets you add more indicators that may potentially have corelation with Stock Prices\n",
    "# Keras RNNs expects an input shape (Batch Size, Timesteps, input_dim)\n",
    "# '.shape[0]' is the number of Rows (Batch Size)\n",
    "# '.shape[1]' is the number of Columns (timesteps)\n",
    "# 'input_dim' is the number of factors that may affect stock prices\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Show the dataset we're working with\n",
    "display(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /root/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 4s 11ms/step - loss: 0.1353\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0319\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0222\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0186\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0153\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0156\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0158\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0129\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0130\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0109\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0118\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0111\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0102\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0103\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 1s 5ms/step - loss: 0.0108\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0121\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0125\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0108\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0105\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0085\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0100\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0100\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0100\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0093\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0105\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0095\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0107\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0080\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0090\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0092\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0097\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0082\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0091\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 1s 4ms/step - loss: 0.0085\n",
      "Epoch 35/100\n",
      "320/327 [============================>.] - ETA: 0s - loss: 0.0086"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "# Building a robust stacked LSTM with dropout regularization\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# Initialising the RNN\n",
    "# Regression is when you predict a continuous value\n",
    "regressor = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "# 'units' is the number of LSTM Memory Cells (Neurons) for higher dimensionality\n",
    "# 'return_sequences = True' because we will add more stacked LSTM Layers\n",
    "# 'input_shape' of x_train\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "# 20% of Neurons will be ignored (10 out of 50 Neurons) to prevent Overfitting\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "# Not need to specify input_shape for second Layer, it knows that we have 50 Neurons from the previous layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# This is the last LSTM Layer. 'return_sequences = false' by default so we leave it out.\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "# 'units = 1' because Output layer has one dimension\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "# Keras documentation recommends 'RMSprop' as a good optimizer for RNNs\n",
    "# Trial and error suggests that 'adam' optimizer is a good choice\n",
    "# loss = 'mean_squared_error' which is good for Regression vs. 'Binary Cross Entropy' previously used for Classification\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "# 'X_train' Independent variables\n",
    "# 'y_train' Output Truths that we compare X_train to.\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n",
    "ticker='DHG.AX'\n",
    "months=72\n",
    "end = datetime.date.today()\n",
    "day=end.day\n",
    "year=end.year-months//12-1\n",
    "month=months%12+1\n",
    "start=datetime.datetime(year,month,day)\n",
    "\n",
    "dataset_test=web.DataReader(ticker,\"yahoo\",start,end)  \n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "# We need 60 previous inputs for each day of the Test_set in 2017\n",
    "# Combine 'dataset_train' and 'dataset_test'\n",
    "# 'axis = 0' for Vertical Concatenation to add rows to the bottom\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# Extract Stock Prices for Test time period, plus 60 days previous\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "# 'reshape' function to get it into a NumPy format\n",
    "inputs = inputs.reshape(-1,1)\n",
    "# Inputs need to be scaled to match the model trained on Scaled Feature\n",
    "inputs = sc.transform(inputs)\n",
    "# The following is pasted from above and modified for Testing, romove all 'Ys'\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "# We need a 3D input so add another dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Predict the Stock Price\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "# We need to inverse the scaling of our prediction to get a Dollar amount\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
